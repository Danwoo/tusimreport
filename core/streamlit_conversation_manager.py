#!/usr/bin/env python3
"""
Streamlit ë„¤ì´í‹°ë¸Œ ëŒ€í™”í˜• ì„œë¹„ìŠ¤ ê´€ë¦¬ì
st.chat_message + st.chat_input ê¸°ë°˜ ëŒ€í™”í˜• Q&A ì‹œìŠ¤í…œ
"""

import streamlit as st
import logging
from datetime import datetime
from typing import Dict, Any, List, Optional
import re

from config.settings import get_llm_model

logger = logging.getLogger(__name__)

class StreamlitConversationManager:
    """Streamlit ë„¤ì´í‹°ë¸Œ ëŒ€í™”í˜• ê´€ë¦¬ì"""

    def __init__(self):
        """ëŒ€í™”í˜• ë§¤ë‹ˆì € ì´ˆê¸°í™”"""
        self._initialize_session_state()
        self.llm = self._get_cached_llm()

        # ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜ë¥¼ ìœ„í•œ í‚¤ì›Œë“œ íŒ¨í„´
        self.question_patterns = {
            "financial": ["ì¬ë¬´", "ë§¤ì¶œ", "ì˜ì—…ì´ìµ", "ìˆœì´ìµ", "ë¶€ì±„", "ìì‚°", "ROE", "ROA", "PER", "PBR", "ë°°ë‹¹", "í˜„ê¸ˆíë¦„"],
            "technical": ["ì°¨íŠ¸", "ê¸°ìˆ ì ", "RSI", "MACD", "ì´í‰ì„ ", "ë³¼ë¦°ì €ë°´ë“œ", "ê³¨ë“ í¬ë¡œìŠ¤", "ì €í•­ì„ ", "ì§€ì§€ì„ ", "ìº”ë“¤"],
            "sentiment": ["ë‰´ìŠ¤", "ì—¬ë¡ ", "ê°ì •", "ì‹œì¥ì‹¬ë¦¬", "íˆ¬ìì‹¬ë¦¬", "ë¶„ìœ„ê¸°", "í‰ê°€", "ì „ë§"],
            "esg": ["ESG", "í™˜ê²½", "ì§€ë°°êµ¬ì¡°", "ì‚¬íšŒì ", "ì§€ì†ê°€ëŠ¥", "ì¹œí™˜ê²½", "íƒ„ì†Œ", "ìœ¤ë¦¬"],
            "forecast": ["ì „ë§", "ëª©í‘œê°€", "ì˜ˆìƒ", "ë¯¸ë˜", "í–¥í›„", "ì•ìœ¼ë¡œ", "ë‚´ë…„", "ì¥ê¸°"],
            "comparison": ["ë¹„êµ", "ë™ì¢…ì—…ê³„", "ê²½ìŸì‚¬", "ì—…ê³„", "ì„¹í„°", "vs", "ëŒ€ë¹„"],
            "institutional": ["ê¸°ê´€", "ìˆ˜ê¸‰", "ë§¤ë§¤", "ì™¸êµ­ì¸", "ê°œì¸", "íˆ¬ìì", "ê±°ë˜ëŸ‰"],
            "risk": ["ìœ„í—˜", "ë¦¬ìŠ¤í¬", "ë³€ë™ì„±", "í•˜ë½", "ì†ì‹¤", "ë¶ˆí™•ì‹¤ì„±", "ìœ„ê¸°"]
        }

        logger.info("StreamlitConversationManager ì´ˆê¸°í™” ì™„ë£Œ")

    def _initialize_session_state(self):
        """Session State ì´ˆê¸°í™”"""
        # ì±„íŒ… ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬
        if "chat_messages" not in st.session_state:
            st.session_state.chat_messages = []

        # ë³´ê³ ì„œ ë° ë¶„ì„ ë°ì´í„°
        if "final_report" not in st.session_state:
            st.session_state.final_report = ""

        if "agent_summaries" not in st.session_state:
            st.session_state.agent_summaries = {}

        # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬
        if "conversation_context" not in st.session_state:
            st.session_state.conversation_context = ""

        # ì‚¬ìš©ì ì„¸ì…˜ ì •ë³´
        if "conversation_started" not in st.session_state:
            st.session_state.conversation_started = False

        logger.debug("ëŒ€í™”í˜• ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ì™„ë£Œ")

    @st.cache_resource
    def _get_cached_llm(_self):
        """LLM ì¸ìŠ¤í„´ìŠ¤ ìºì‹± (ì„¸ì…˜ê°„ ê³µìœ )"""
        try:
            provider, model_name, api_key = get_llm_model()

            if provider == "gemini":
                from langchain_google_genai import ChatGoogleGenerativeAI
                return ChatGoogleGenerativeAI(
                    model=model_name,
                    temperature=0.1,
                    google_api_key=api_key
                )
            else:
                from langchain_openai import ChatOpenAI
                return ChatOpenAI(
                    model=model_name,
                    temperature=0.1,
                    api_key=api_key
                )
        except Exception as e:
            logger.error(f"LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
            return None

    def is_conversation_available(self) -> bool:
        """ëŒ€í™”í˜• ì„œë¹„ìŠ¤ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        return bool(
            st.session_state.get("final_report") or
            st.session_state.get("agent_summaries")
        )

    def render_conversation_interface(self):
        """ë©”ì¸ ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤ ë Œë”ë§"""

        if not self.is_conversation_available():
            st.info("ğŸ’¬ ë¶„ì„ ë³´ê³ ì„œê°€ ìƒì„±ëœ í›„ ëŒ€í™”í˜• Q&Aë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            return

        # ëŒ€í™”í˜• ì„œë¹„ìŠ¤ ì œëª©
        st.markdown("### ğŸ’¬ íˆ¬ì ë¶„ì„ Q&A")
        st.markdown("ë¶„ì„ ë³´ê³ ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ê¶ê¸ˆí•œ ì ì„ ììœ ë¡­ê²Œ ë¬¼ì–´ë³´ì„¸ìš”!")

        # ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ
        self._render_chat_history()

        # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
        self._handle_user_input()

        # ëŒ€í™” ì‹œì‘ ì•ˆë‚´
        # ğŸ”§ Session state ë°©ì–´ì  ì´ˆê¸°í™”
        if "chat_messages" not in st.session_state:
            st.session_state.chat_messages = []

        if not st.session_state.chat_messages:
            self._show_conversation_starter()

    def _render_chat_history(self):
        """ì±„íŒ… íˆìŠ¤í† ë¦¬ ë Œë”ë§"""
        # ğŸ”§ Session state ë°©ì–´ì  ì´ˆê¸°í™”
        if "chat_messages" not in st.session_state:
            st.session_state.chat_messages = []

        for message in st.session_state.chat_messages:
            with st.chat_message(message["role"]):
                if message["role"] == "assistant":
                    # AI ì‘ë‹µì—ëŠ” ì¶”ê°€ ì •ë³´ í‘œì‹œ
                    st.markdown(message["content"])
                    if "timestamp" in message:
                        st.caption(f"ì‘ë‹µ ì‹œê°„: {message['timestamp']}")
                else:
                    # ì‚¬ìš©ì ë©”ì‹œì§€
                    st.markdown(message["content"])

    def _handle_user_input(self):
        """ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬"""
        # Streamlit ë„¤ì´í‹°ë¸Œ ì±„íŒ… ì…ë ¥ (ë¶„ì„ ìœ í˜•ë³„ ìœ ë‹ˆí¬ í‚¤)
        import time
        analysis_type = st.session_state.get('current_analysis_type', 'default')
        timestamp = int(time.time() * 1000)  # ë°€ë¦¬ì´ˆ íƒ€ì„ìŠ¤íƒ¬í”„
        unique_key = f"conversation_input_{analysis_type}_{timestamp}_{hash(str(st.session_state.get('final_report', '')))}"
        if prompt := st.chat_input(
            "ë¶„ì„ ë³´ê³ ì„œì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”...",
            key=unique_key
        ):
            # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            user_message = {
                "role": "user",
                "content": prompt,
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
            st.session_state.chat_messages.append(user_message)

            # ì‚¬ìš©ì ë©”ì‹œì§€ ì¦‰ì‹œ í‘œì‹œ
            with st.chat_message("user"):
                st.markdown(prompt)

            # AI ì‘ë‹µ ìƒì„± ë° í‘œì‹œ
            with st.chat_message("assistant"):
                with st.spinner("ë¶„ì„ ì¤‘..."):
                    try:
                        response = self._generate_contextual_response(prompt)
                        st.markdown(response)

                        # AI ì‘ë‹µ ì„¸ì…˜ì— ì €ì¥
                        assistant_message = {
                            "role": "assistant",
                            "content": response,
                            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                        }
                        st.session_state.chat_messages.append(assistant_message)

                        # ëŒ€í™” ì‹œì‘ í”Œë˜ê·¸ ì„¤ì •
                        st.session_state.conversation_started = True

                    except Exception as e:
                        error_msg = f"ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                        st.error(error_msg)

                        # ì˜¤ë¥˜ ë©”ì‹œì§€ë„ íˆìŠ¤í† ë¦¬ì— ì €ì¥
                        error_message = {
                            "role": "assistant",
                            "content": error_msg,
                            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                        }
                        st.session_state.chat_messages.append(error_message)

    def _generate_contextual_response(self, question: str) -> str:
        """ë³´ê³ ì„œ ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì‘ë‹µ ìƒì„±"""
        try:
            # ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜
            question_type = self._classify_question_type(question)

            # ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            relevant_context = self._get_relevant_context(question, question_type)

            # ëŒ€í™” íˆìŠ¤í† ë¦¬ ìš”ì•½ (ìµœê·¼ 3ê°œ ë©”ì‹œì§€)
            conversation_history = self._get_recent_conversation_history(3)

            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            context_prompt = f"""
ë‹¹ì‹ ì€ ì „ë¬¸ íˆ¬ì ë¶„ì„ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì¢…í•© íˆ¬ì ë¶„ì„ ë³´ê³ ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.

## ë¶„ì„ ë³´ê³ ì„œ ë‚´ìš©:
{relevant_context}

## ìµœê·¼ ëŒ€í™” ë‚´ì—­:
{conversation_history}

## ì‚¬ìš©ì ì§ˆë¬¸:
{question}

## ë‹µë³€ ê°€ì´ë“œë¼ì¸:
- ë³´ê³ ì„œì˜ ë‚´ìš©ì„ ê·¼ê±°ë¡œ ë‹µë³€í•˜ì„¸ìš”
- êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë‚˜ ë°ì´í„°ê°€ ìˆë‹¤ë©´ ì¸ìš©í•˜ì„¸ìš”
- ë¶ˆí™•ì‹¤í•œ ë‚´ìš©ì€ ëª…í™•íˆ êµ¬ë¶„í•˜ì—¬ í‘œí˜„í•˜ì„¸ìš”
- íˆ¬ì ì¡°ì–¸ì´ ì•„ë‹Œ ë¶„ì„ ì •ë³´ì„ì„ ëª…ì‹œí•˜ì„¸ìš”
- ê°„ê²°í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ë‹µë³€í•˜ì„¸ìš”

ë‹µë³€:
"""

            # LLM í˜¸ì¶œ
            if self.llm:
                response = self.llm.invoke(context_prompt)
                return response.content if hasattr(response, 'content') else str(response)
            else:
                return "ì£„ì†¡í•©ë‹ˆë‹¤. AI ì„œë¹„ìŠ¤ì— ì¼ì‹œì ì¸ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

        except Exception as e:
            logger.error(f"ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            return f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

    def _classify_question_type(self, question: str) -> str:
        """ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜"""
        question_lower = question.lower()

        # ê° ìœ í˜•ë³„ í‚¤ì›Œë“œ ë§¤ì¹­
        for category, keywords in self.question_patterns.items():
            if any(keyword in question_lower for keyword in keywords):
                return category

        return "general"

    def _get_relevant_context(self, question: str, question_type: str) -> str:
        """ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        contexts = []

        # ìµœì¢… ë³´ê³ ì„œì—ì„œ ê´€ë ¨ ì„¹ì…˜ ì¶”ì¶œ
        if st.session_state.final_report:
            report_sections = self._extract_relevant_report_sections(
                question, st.session_state.final_report
            )
            if report_sections:
                contexts.append(f"## ì¢…í•© ë³´ê³ ì„œ ê´€ë ¨ ë‚´ìš©:\n{report_sections}")

        # ì—ì´ì „íŠ¸ë³„ ë¶„ì„ì—ì„œ ê´€ë ¨ ë‚´ìš© ì¶”ì¶œ
        if st.session_state.agent_summaries:
            agent_contexts = self._extract_relevant_agent_analysis(
                question, question_type, st.session_state.agent_summaries
            )
            if agent_contexts:
                contexts.append(f"## ì „ë¬¸ê°€ ë¶„ì„ ê´€ë ¨ ë‚´ìš©:\n{agent_contexts}")

        # ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (5000ì)
        combined_context = "\n\n".join(contexts)
        if len(combined_context) > 5000:
            combined_context = combined_context[:5000] + "..."

        return combined_context

    def _extract_relevant_report_sections(self, question: str, report: str) -> str:
        """ë³´ê³ ì„œì—ì„œ ê´€ë ¨ ì„¹ì…˜ ì¶”ì¶œ"""
        # ì§ˆë¬¸ì˜ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = re.findall(r'\b\w{2,}\b', question.lower())

        # ë³´ê³ ì„œë¥¼ ì„¹ì…˜ë³„ë¡œ ë¶„í•  (## ë˜ëŠ” ### ê¸°ì¤€)
        sections = re.split(r'\n##+ ', report)

        relevant_sections = []
        for section in sections:
            section_lower = section.lower()
            if any(keyword in section_lower for keyword in keywords):
                # ì„¹ì…˜ ê¸¸ì´ ì œí•œ (1000ì)
                if len(section) > 1000:
                    section = section[:1000] + "..."
                relevant_sections.append(section)

        return "\n\n".join(relevant_sections[:3])  # ìµœëŒ€ 3ê°œ ì„¹ì…˜

    def _extract_relevant_agent_analysis(
        self,
        question: str,
        question_type: str,
        agent_summaries: Dict[str, str]
    ) -> str:
        """ì—ì´ì „íŠ¸ ë¶„ì„ì—ì„œ ê´€ë ¨ ë‚´ìš© ì¶”ì¶œ"""

        # ì§ˆë¬¸ ìœ í˜•ì— ë”°ë¥¸ ê´€ë ¨ ì—ì´ì „íŠ¸ ë§¤í•‘
        relevant_agents = {
            "financial": ["financial_expert"],
            "technical": ["advanced_technical_expert"],
            "sentiment": ["sentiment_expert"],
            "esg": ["esg_expert"],
            "forecast": ["financial_expert", "advanced_technical_expert"],
            "comparison": ["comparative_expert"],
            "institutional": ["institutional_trading_expert"],
            "risk": ["financial_expert", "advanced_technical_expert"]
        }

        target_agents = relevant_agents.get(question_type, list(agent_summaries.keys()))

        relevant_analyses = []
        for agent_name in target_agents:
            if agent_name in agent_summaries:
                analysis = agent_summaries[agent_name]
                if len(analysis) > 800:
                    analysis = analysis[:800] + "..."
                relevant_analyses.append(f"**{agent_name}**: {analysis}")

        return "\n\n".join(relevant_analyses[:2])  # ìµœëŒ€ 2ê°œ ì—ì´ì „íŠ¸

    def _get_recent_conversation_history(self, num_messages: int) -> str:
        """ìµœê·¼ ëŒ€í™” íˆìŠ¤í† ë¦¬ ê°€ì ¸ì˜¤ê¸°"""
        if not st.session_state.chat_messages:
            return "ì´ì „ ëŒ€í™” ì—†ìŒ"

        recent_messages = st.session_state.chat_messages[-num_messages*2:]  # Q&A ìŒ ê³ ë ¤

        history_text = []
        for msg in recent_messages:
            role = "ì‚¬ìš©ì" if msg["role"] == "user" else "AI"
            content = msg["content"][:200] + "..." if len(msg["content"]) > 200 else msg["content"]
            history_text.append(f"{role}: {content}")

        return "\n".join(history_text)

    def _show_conversation_starter(self):
        """ëŒ€í™” ì‹œì‘ ì•ˆë‚´ ë° ì˜ˆì‹œ ì§ˆë¬¸"""
        st.markdown("#### ğŸ’¡ ì´ëŸ° ì§ˆë¬¸ì„ í•´ë³´ì„¸ìš”:")

        example_questions = [
            "ì´ ê¸°ì—…ì˜ ì¬ë¬´ìƒíƒœëŠ” ì–´ë–¤ê°€ìš”?",
            "ì£¼ê°€ ì „ë§ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            "íˆ¬ì ì‹œ ì£¼ì˜í•  ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ë™ì¢…ì—…ê³„ ëŒ€ë¹„ ì–´ë–¤ ìœ„ì¹˜ì¸ê°€ìš”?",
            "ìµœê·¼ ë‰´ìŠ¤ê°€ ì£¼ê°€ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì€?",
            "ê¸°ìˆ ì  ë¶„ì„ ê´€ì ì—ì„œ ë§¤ìˆ˜ ì‹œì ì¸ê°€ìš”?"
        ]

        cols = st.columns(2)
        for i, question in enumerate(example_questions):
            with cols[i % 2]:
                if st.button(
                    question,
                    key=f"example_q_{i}",
                    use_container_width=True,
                    help="í´ë¦­í•˜ë©´ ìë™ìœ¼ë¡œ ì§ˆë¬¸ì´ ì…ë ¥ë©ë‹ˆë‹¤"
                ):
                    # ì˜ˆì‹œ ì§ˆë¬¸ì„ ì±„íŒ…ì— ì¶”ê°€í•˜ê³  ë‹µë³€ ìƒì„±
                    st.session_state.chat_messages.append({
                        "role": "user",
                        "content": question,
                        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    })
                    st.rerun()

    def clear_conversation_history(self):
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”"""
        if st.button("ğŸ—‘ï¸ ëŒ€í™” ë‚´ì—­ ì´ˆê¸°í™”", help="ëª¨ë“  ëŒ€í™” ë‚´ì—­ì„ ì‚­ì œí•©ë‹ˆë‹¤"):
            st.session_state.chat_messages = []
            st.session_state.conversation_started = False
            st.success("ëŒ€í™” ë‚´ì—­ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.rerun()

    def get_conversation_stats(self) -> Dict[str, Any]:
        """ëŒ€í™” í†µê³„ ì •ë³´ ë°˜í™˜"""
        if not st.session_state.chat_messages:
            return {
                "total_messages": 0,
                "user_questions": 0,
                "ai_responses": 0,
                "conversation_started": False
            }

        user_questions = len([msg for msg in st.session_state.chat_messages if msg["role"] == "user"])
        ai_responses = len([msg for msg in st.session_state.chat_messages if msg["role"] == "assistant"])

        return {
            "total_messages": len(st.session_state.chat_messages),
            "user_questions": user_questions,
            "ai_responses": ai_responses,
            "conversation_started": st.session_state.get("conversation_started", False)
        }

# ğŸ”§ ì „ì—­ ëŒ€í™”í˜• ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤ (ì‹±ê¸€í†¤)
_conversation_manager = None

def get_conversation_manager():
    """ì „ì—­ ëŒ€í™”í˜• ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤ (ì‹±ê¸€í†¤)"""
    global _conversation_manager
    if _conversation_manager is None:
        _conversation_manager = StreamlitConversationManager()
    return _conversation_manager